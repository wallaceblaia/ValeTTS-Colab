{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üé§ ValeTTS VITS2 English Training\n",
        "## Treinamento Completo do Modelo VITS2 para Ingl√™s\n",
        "\n",
        "**Status**: ‚úÖ **FUNCIONAL** - Todas as dimens√µes corrigidas\n",
        "\n",
        "### üöÄ Recursos:\n",
        "- ‚úÖ Suporte completo ao ingl√™s com phonemes\n",
        "- ‚úÖ Dimens√µes do modelo compat√≠veis\n",
        "- ‚úÖ Configura√ß√£o debug e produ√ß√£o\n",
        "- ‚úÖ Multi-speaker (52 falantes)\n",
        "- ‚úÖ Dataset: 22.910 amostras\n",
        "\n",
        "### ‚öôÔ∏è Configura√ß√µes:\n",
        "- **Debug**: 100 amostras, 3 √©pocas (teste r√°pido)\n",
        "- **Produ√ß√£o**: 20.619 amostras, 200 √©pocas (treinamento completo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CONFIGURA√á√ÉO DO MODO DE TREINAMENTO ===\n",
        "DEBUG_MODE = True # @param {type:\"boolean\"}\n",
        "USE_DRIVE = True # @param {type:\"boolean\"}\n",
        "MOUNT_DRIVE = True # @param {type:\"boolean\"}\n",
        "\n",
        "# Configura√ß√£o baseada no modo\n",
        "if DEBUG_MODE:\n",
        "    print(\"üêõ MODO DEBUG: Treinamento r√°pido para teste\")\n",
        "    EPOCHS = 3\n",
        "    MAX_SAMPLES = 100\n",
        "    CONFIG_NAME = \"vits2_english_debug\"\n",
        "else:\n",
        "    print(\"üöÄ MODO PRODU√á√ÉO: Treinamento completo\")\n",
        "    EPOCHS = 200\n",
        "    MAX_SAMPLES = None\n",
        "    CONFIG_NAME = \"vits2_english_production\"\n",
        "\n",
        "print(f\"üìä Configura√ß√£o: {CONFIG_NAME}\")\n",
        "print(f\"üîÑ √âpocas: {EPOCHS}\")\n",
        "print(f\"üìà Amostras: {MAX_SAMPLES if MAX_SAMPLES else 'Todas (~22.910)'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CONFIGURA√á√ÉO DO SISTEMA E CLONAGEM ===\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def run_command(cmd, description):\n",
        "    \"\"\"Executa comando com output em tempo real.\"\"\"\n",
        "    print(f\"üîÑ {description}\")\n",
        "    process = subprocess.Popen(\n",
        "        cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
        "        universal_newlines=True, bufsize=1\n",
        "    )\n",
        "\n",
        "    for line in process.stdout:\n",
        "        print(line.rstrip())\n",
        "\n",
        "    process.wait()\n",
        "    if process.returncode != 0:\n",
        "        raise RuntimeError(f\"Comando falhou: {cmd}\")\n",
        "    print(f\"‚úÖ {description} - Conclu√≠do\\n\")\n",
        "\n",
        "# Montar Google Drive se necess√°rio\n",
        "if MOUNT_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    if USE_DRIVE:\n",
        "        drive_path = '/content/drive/MyDrive/ValeTTS'\n",
        "        os.makedirs(drive_path, exist_ok=True)\n",
        "        os.chdir(drive_path)\n",
        "        print(f\"üìÅ Diret√≥rio de trabalho: {drive_path}\")\n",
        "\n",
        "# Verificar GPU\n",
        "run_command(\"nvidia-smi\", \"Verificando GPU dispon√≠vel\")\n",
        "\n",
        "# Clonar reposit√≥rio\n",
        "if not os.path.exists('ValeTTS'):\n",
        "    run_command(\n",
        "        \"git clone https://github.com/wallaceblaia/ValeTTS-Colab.git ValeTTS\",\n",
        "        \"Clonando reposit√≥rio ValeTTS\"\n",
        "    )\n",
        "else:\n",
        "    print(\"üìÅ Reposit√≥rio j√° existe\")\n",
        "\n",
        "os.chdir('ValeTTS')\n",
        "run_command(\"git pull origin main\", \"Atualizando reposit√≥rio\")\n",
        "print(f\"üìç Diret√≥rio atual: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === INSTALA√á√ÉO DE DEPEND√äNCIAS ===\n",
        "# Instalar depend√™ncias do sistema\n",
        "run_command(\n",
        "    \"apt-get update && apt-get install -y espeak espeak-data libespeak1 libespeak-dev ffmpeg\",\n",
        "    \"Instalando depend√™ncias do sistema\"\n",
        ")\n",
        "\n",
        "# Instalar depend√™ncias Python\n",
        "run_command(\n",
        "    \"pip install -e .\",\n",
        "    \"Instalando ValeTTS em modo desenvolvimento\"\n",
        ")\n",
        "\n",
        "# Verificar instala√ß√£o\n",
        "run_command(\n",
        "    \"python -c 'import valetts; print(f\\\"‚úÖ ValeTTS instalado: {valetts.__version__}\\\")'\",\n",
        "    \"Verificando instala√ß√£o\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === DOWNLOAD DO DATASET ===\n",
        "dataset_path = \"data/generated/Dataset-Unificado\"\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"üì• Dataset n√£o encontrado localmente\")\n",
        "    print(\"üí° Certifique-se de ter o dataset dispon√≠vel em:\")\n",
        "    print(\"   - Google Drive: /content/drive/MyDrive/ValeTTS/data/generated/Dataset-Unificado\")\n",
        "    print(\"   - Ou fa√ßa upload manual do dataset\")\n",
        "\n",
        "    # Verificar se existe no Drive\n",
        "    drive_dataset = \"/content/drive/MyDrive/ValeTTS/data/generated/Dataset-Unificado\"\n",
        "    if os.path.exists(drive_dataset):\n",
        "        print(f\"‚úÖ Dataset encontrado no Drive: {drive_dataset}\")\n",
        "        print(\"üîó Criando link simb√≥lico...\")\n",
        "        os.makedirs(\"data/generated\", exist_ok=True)\n",
        "        os.symlink(drive_dataset, dataset_path)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Dataset n√£o encontrado!\")\n",
        "        print(\"üìã Use um dos m√©todos abaixo:\")\n",
        "        print(\"1. Upload manual via interface do Colab\")\n",
        "        print(\"2. Download direto (substitua o link):\")\n",
        "        print(\"   !gdown --folder 'LINK_DO_GOOGLE_DRIVE_AQUI'\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset j√° existe\")\n",
        "\n",
        "# Verificar dataset\n",
        "metadata_file = f\"{dataset_path}/metadata.csv\"\n",
        "if os.path.exists(metadata_file):\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(metadata_file)\n",
        "    print(f\"üìä Dataset carregado: {len(df)} amostras\")\n",
        "    print(f\"üéôÔ∏è Falantes √∫nicos: {df['speaker_id'].nunique()}\")\n",
        "    print(f\"üåç Idiomas: {df['locale'].unique() if 'locale' in df.columns else 'N/A'}\")\n",
        "\n",
        "    # Mostrar amostra dos dados\n",
        "    print(\"\\nüìã Amostra dos dados:\")\n",
        "    print(df.head(3)[['speaker_id', 'text', 'locale']].to_string())\n",
        "else:\n",
        "    print(\"‚ùå Arquivo metadata.csv n√£o encontrado!\")\n",
        "    print(\"üí° Verifique se o dataset foi baixado corretamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CONFIGURA√á√ÉO DIN√ÇMICA DO MODELO ===\n",
        "import yaml\n",
        "\n",
        "# Configura√ß√£o base do modelo com dimens√µes compat√≠veis\n",
        "if DEBUG_MODE:\n",
        "    # Debug: dimens√µes reduzidas mas compat√≠veis\n",
        "    model_config = {\n",
        "        \"text_encoder_hidden_dim\": 128,\n",
        "        \"latent_dim\": 128,\n",
        "        \"speaker_embedding_dim\": 256,  # Igual ao generator_initial_channels\n",
        "        \"generator_initial_channels\": 256,\n",
        "        \"decoder_hidden_dim\": 256,  # Igual ao generator_initial_channels\n",
        "    }\n",
        "else:\n",
        "    # Produ√ß√£o: dimens√µes completas\n",
        "    model_config = {\n",
        "        \"text_encoder_hidden_dim\": 192,\n",
        "        \"latent_dim\": 192,\n",
        "        \"speaker_embedding_dim\": 512,  # Igual ao generator_initial_channels\n",
        "        \"generator_initial_channels\": 512,\n",
        "        \"decoder_hidden_dim\": 512,  # Igual ao generator_initial_channels\n",
        "    }\n",
        "\n",
        "# Configura√ß√£o completa do YAML\n",
        "config = {\n",
        "    \"model\": {\n",
        "        \"name\": \"VITS2\",\n",
        "        \"mel_channels\": 80,\n",
        "        \"n_speakers\": 52,\n",
        "        \"text_processor\": \"english\",\n",
        "        \"inference_only\": False,\n",
        "        **model_config\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"learning_rate\": 2.0e-4,\n",
        "        \"batch_size\": 16,\n",
        "        \"max_epochs\": EPOCHS,\n",
        "        \"accumulate_grad_batches\": 1,\n",
        "        \"max_grad_norm\": 1.0,\n",
        "        \"mel_loss_weight\": 45.0,\n",
        "        \"kl_loss_weight\": 1.0,\n",
        "        \"adv_loss_weight\": 1.0,\n",
        "        \"fm_loss_weight\": 2.0,\n",
        "        \"duration_loss_weight\": 1.0,\n",
        "        \"use_amp\": True,\n",
        "        \"gradient_clip_val\": 1.0,\n",
        "        \"discriminator_update_frequency\": 1,\n",
        "        \"scheduler\": {\n",
        "            \"name\": \"ReduceLROnPlateau\",\n",
        "            \"mode\": \"min\",\n",
        "            \"factor\": 0.5,\n",
        "            \"patience\": 15 if not DEBUG_MODE else 5,\n",
        "            \"min_lr\": 1.0e-6\n",
        "        }\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"dataset_format\": \"valetts\",\n",
        "        \"data_dir\": \"data/generated/Dataset-Unificado\",\n",
        "        \"metadata_file\": \"data/generated/Dataset-Unificado/metadata.csv\",\n",
        "        \"language\": \"en-us\",\n",
        "        \"locale_column\": \"locale\",\n",
        "        \"text_processor\": {\n",
        "            \"use_phonemes\": True,\n",
        "            \"normalize_numbers\": True,\n",
        "            \"normalize_whitespace\": True,\n",
        "            \"lowercase\": True\n",
        "        },\n",
        "        \"sample_rate\": 22050,\n",
        "        \"n_mels\": 80,\n",
        "        \"n_fft\": 1024,\n",
        "        \"hop_length\": 256,\n",
        "        \"win_length\": 1024,\n",
        "        \"num_workers\": 4,\n",
        "        \"pin_memory\": True,\n",
        "        \"persistent_workers\": True,\n",
        "        \"use_augmentation\": True,\n",
        "        \"volume_range\": [0.9, 1.1],\n",
        "        \"pitch_range\": [-1, 1]\n",
        "    },\n",
        "    \"logging\": {\n",
        "        \"log_dir\": \"logs\",\n",
        "        \"experiment_name\": f\"vits2_english_{CONFIG_NAME.split('_')[-1]}\",\n",
        "        \"checkpoint\": {\n",
        "            \"dirpath\": f\"checkpoints/vits2_english_{CONFIG_NAME.split('_')[-1]}\",\n",
        "            \"filename\": f\"vits2_english-{{epoch:03d}}-{{epoch/val_loss_total:.3f}}\",\n",
        "            \"monitor\": \"epoch/val_loss_total\",\n",
        "            \"mode\": \"min\",\n",
        "            \"save_top_k\": 3 if DEBUG_MODE else 5,\n",
        "            \"save_last\": True,\n",
        "            \"every_n_epochs\": 1 if DEBUG_MODE else 10\n",
        "        },\n",
        "        \"early_stopping\": {\n",
        "            \"monitor\": \"epoch/val_loss_total\",\n",
        "            \"mode\": \"min\",\n",
        "            \"patience\": 10 if DEBUG_MODE else 30,\n",
        "            \"min_delta\": 0.001\n",
        "        },\n",
        "        \"tensorboard\": {\n",
        "            \"save_dir\": \"logs/tensorboard\",\n",
        "            \"name\": f\"vits2_english_{CONFIG_NAME.split('_')[-1]}\"\n",
        "        }\n",
        "    },\n",
        "    \"hardware\": {\n",
        "        \"accelerator\": \"gpu\",\n",
        "        \"devices\": 1,\n",
        "        \"precision\": \"16-mixed\",\n",
        "        \"strategy\": \"auto\"\n",
        "    },\n",
        "    \"validation\": {\n",
        "        \"val_check_interval\": 1.0,\n",
        "        \"generate_samples\": True,\n",
        "        \"sample_every_n_epochs\": 1 if DEBUG_MODE else 10,\n",
        "        \"limit_val_batches\": 1.0\n",
        "    },\n",
        "    \"dataset_config\": {\n",
        "        \"expected_locale\": \"en\",\n",
        "        \"validate_files\": True,\n",
        "        \"cache_preprocessing\": True\n",
        "    },\n",
        "    \"llm_monitor\": {\n",
        "        \"enabled\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Adicionar limita√ß√£o de amostras para debug\n",
        "if DEBUG_MODE:\n",
        "    config[\"data\"][\"max_samples_debug\"] = MAX_SAMPLES\n",
        "\n",
        "# Criar diret√≥rios necess√°rios\n",
        "os.makedirs(\"configs/training\", exist_ok=True)\n",
        "os.makedirs(config[\"logging\"][\"checkpoint\"][\"dirpath\"], exist_ok=True)\n",
        "os.makedirs(\"logs/tensorboard\", exist_ok=True)\n",
        "\n",
        "# Salvar configura√ß√£o\n",
        "config_path = f\"configs/training/{CONFIG_NAME}.yaml\"\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(config, f, default_flow_style=False, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Configura√ß√£o criada: {config_path}\")\n",
        "print(f\"üéØ Modo: {CONFIG_NAME.upper()}\")\n",
        "print(f\"üìä √âpocas: {EPOCHS}\")\n",
        "print(f\"üé§ Falantes: {config['model']['n_speakers']}\")\n",
        "print(f\"üíæ Dimens√µes do modelo (compat√≠veis):\")\n",
        "print(f\"   - Hidden: {config['model']['text_encoder_hidden_dim']}\")\n",
        "print(f\"   - Latent: {config['model']['latent_dim']}\")\n",
        "print(f\"   - Speaker: {config['model']['speaker_embedding_dim']}\")\n",
        "print(f\"   - Generator: {config['model']['generator_initial_channels']}\")\n",
        "print(f\"   - Decoder: {config['model']['decoder_hidden_dim']}\")\n",
        "\n",
        "# Verificar compatibilidade de dimens√µes\n",
        "if config['model']['speaker_embedding_dim'] == config['model']['decoder_hidden_dim']:\n",
        "    print(\"‚úÖ Dimens√µes compat√≠veis - Sem erro de tensor!\")\n",
        "else:\n",
        "    print(\"‚ùå AVISO: Dimens√µes incompat√≠veis detectadas!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === INICIAR TREINAMENTO ===\n",
        "print(f\"üöÄ Iniciando treinamento VITS2 - Modo: {CONFIG_NAME.upper()}\")\n",
        "print(f\"üìÅ Configura√ß√£o: {config_path}\")\n",
        "print(f\"‚è±Ô∏è Estimativa: {'~5 min' if DEBUG_MODE else '~8-12 horas'}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Executar treinamento\n",
        "cmd = f\"python scripts/train_vits2.py --config {config_path} --disable-llm\"\n",
        "run_command(cmd, f\"Treinamento VITS2 {CONFIG_NAME.upper()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\")\n",
        "print(f\"üìÅ Checkpoints salvos em: {config['logging']['checkpoint']['dirpath']}/\")\n",
        "print(f\"üìä Logs dispon√≠veis em: logs/tensorboard/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === DOWNLOAD DOS RESULTADOS ===\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "import glob\n",
        "\n",
        "# Criar arquivo ZIP com resultados\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_filename = f\"valetts_vits2_english_{CONFIG_NAME.split('_')[-1]}_{timestamp}.zip\"\n",
        "\n",
        "print(f\"üì¶ Criando arquivo ZIP: {zip_filename}\")\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Adicionar checkpoints\n",
        "    checkpoint_dir = config[\"logging\"][\"checkpoint\"][\"dirpath\"]\n",
        "    if os.path.exists(checkpoint_dir):\n",
        "        for root, dirs, files in os.walk(checkpoint_dir):\n",
        "            for file in files:\n",
        "                if file.endswith('.ckpt'):\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    zipf.write(file_path, os.path.relpath(file_path, '.'))\n",
        "\n",
        "    # Adicionar configura√ß√£o\n",
        "    zipf.write(config_path, config_path)\n",
        "\n",
        "    # Adicionar amostras geradas\n",
        "    if os.path.exists(\"samples\"):\n",
        "        for root, dirs, files in os.walk(\"samples\"):\n",
        "            for file in files:\n",
        "                if file.endswith('.wav'):\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    zipf.write(file_path, os.path.relpath(file_path, '.'))\n",
        "\n",
        "    # Adicionar logs principais\n",
        "    if os.path.exists(\"logs/training.log\"):\n",
        "        zipf.write(\"logs/training.log\", \"logs/training.log\")\n",
        "\n",
        "print(f\"‚úÖ Arquivo criado: {zip_filename}\")\n",
        "print(f\"üíæ Tamanho: {os.path.getsize(zip_filename) / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "# Download no Colab\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import files\n",
        "    print(\"‚¨áÔ∏è Iniciando download...\")\n",
        "    files.download(zip_filename)\n",
        "    print(\"‚úÖ Download conclu√≠do!\")\n",
        "\n",
        "print(\"\\nüéØ TREINAMENTO FINALIZADO!\")\n",
        "print(f\"üìä Modo: {CONFIG_NAME.upper()}\")\n",
        "print(f\"‚è±Ô∏è Status: {'Teste conclu√≠do' if DEBUG_MODE else 'Produ√ß√£o conclu√≠da'}\")\n",
        "print(f\"üì¶ Resultados salvos em: {zip_filename}\")\n",
        "\n",
        "# Encontrar e mostrar checkpoints dispon√≠veis\n",
        "checkpoint_dir = config[\"logging\"][\"checkpoint\"][\"dirpath\"]\n",
        "checkpoints = glob.glob(f\"{checkpoint_dir}/*.ckpt\")\n",
        "if checkpoints:\n",
        "    print(f\"\\nüìÅ Checkpoints dispon√≠veis ({len(checkpoints)}):\")\n",
        "    for ckpt in sorted(checkpoints)[-3:]:  # Mostrar √∫ltimos 3\n",
        "        size_mb = os.path.getsize(ckpt) / 1024 / 1024\n",
        "        print(f\"   üì¶ {os.path.basename(ckpt)} ({size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Nenhum checkpoint encontrado\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
