# ğŸ™ï¸ ValeTTS - Sistema TTS HÃ­brido AvanÃ§ado

**Sistema de Text-to-Speech com arquitetura hÃ­brida: VITS2 + Meta-Learning + BigVGAN-v2 + Controle ProsÃ³dico**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wallacemt/ValeTTS/blob/main/colab_training_vits2.ipynb)

## ğŸš€ InÃ­cio RÃ¡pido no Google Colab

**Treinamento com performance 25-200x mais rÃ¡pida que CPU local!**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wallacemt/ValeTTS/blob/main/colab_training_vits2.ipynb)

1. **Clique no botÃ£o acima** para abrir no Google Colab
2. **Configure sua API OpenRouter** (opcional, para monitor LLM)
3. **Execute todas as cÃ©lulas** - o sistema farÃ¡ tudo automaticamente
4. **Aguarde o treinamento** - monitoramento via TensorBoard integrado

## ğŸ—ï¸ Arquitetura

### ğŸ¯ Componentes Principais

- **ğŸµ VITS2**: Modelo base de sÃ­ntese neural end-to-end
- **ğŸ§  Meta-Learning (MAML)**: AdaptaÃ§Ã£o rÃ¡pida para novos speakers
- **ğŸ”Š BigVGAN-v2**: Vocoder neural de alta qualidade
- **ğŸ­ Controle ProsÃ³dico**: ManipulaÃ§Ã£o de entonaÃ§Ã£o, ritmo e emoÃ§Ã£o
- **ğŸ¤– Monitor LLM**: OtimizaÃ§Ã£o inteligente durante treinamento

### ğŸ“Š Performance

| Ambiente | GPU | Performance | Speedup vs Local |
|----------|-----|-------------|------------------|
| **Local** | CPU | 0.08 it/s | 1x (baseline) |
| **Colab** | T4 | 1-2 it/s | 25-50x |
| **Colab Pro** | P100 | 2-3 it/s | 50-75x |
| **Colab Pro+** | V100 | 3-5 it/s | 75-125x |
| **Colab Pro+** | A100 | 5-8 it/s | 125-200x |

## ğŸ› ï¸ InstalaÃ§Ã£o Local

### PrÃ©-requisitos

```bash
# Python 3.8+
python --version

# Git
git --version
```

### Setup

```bash
# Clone do repositÃ³rio
git clone https://github.com/wallacemt/ValeTTS.git
cd ValeTTS

# Instalar dependÃªncias
pip install -r requirements.txt

# Instalar projeto
pip install -e .
```

## ğŸ¯ Uso

### ğŸš€ Treinamento Local

```bash
# Comando bÃ¡sico
python scripts/train_vits2.py --config configs/training/vits2_dataset_unificado.yaml

# Com monitor LLM (configure OPENROUTER_API_KEY)
export OPENROUTER_API_KEY="sua_api_key"
python scripts/train_vits2.py --config configs/training/vits2_dataset_unificado.yaml

# Resumir treinamento
python scripts/train_vits2.py --config configs/training/vits2_dataset_unificado.yaml --resume logs/checkpoints/last.ckpt
```

### ğŸ™ï¸ InferÃªncia

```bash
# SÃ­ntese bÃ¡sica
python scripts/inference.py --text "OlÃ¡, mundo!" --speaker_id 0 --output audio_output.wav

# Com controle prosÃ³dico
python scripts/inference.py --text "OlÃ¡, mundo!" --speaker_id 0 --emotion happy --speed 1.2 --pitch 1.1
```

## ğŸ“ Estrutura do Projeto

```
ValeTTS/
â”œâ”€â”€ ğŸ““ colab_training_vits2.ipynb    # Notebook para Google Colab
â”œâ”€â”€ ğŸ valetts/                      # MÃ³dulo principal
â”‚   â”œâ”€â”€ ğŸµ models/                   # Modelos (VITS2, BigVGAN, etc.)
â”‚   â”œâ”€â”€ ğŸ“Š data/                     # Datasets e loaders
â”‚   â”œâ”€â”€ ğŸ‹ï¸ training/                 # Sistema de treinamento
â”‚   â”œâ”€â”€ ğŸ™ï¸ inference/               # Sistema de inferÃªncia
â”‚   â”œâ”€â”€ ğŸ“ˆ evaluation/               # MÃ©tricas e avaliaÃ§Ã£o
â”‚   â””â”€â”€ ğŸ› ï¸ utils/                    # UtilitÃ¡rios
â”œâ”€â”€ ğŸ”§ scripts/                      # Scripts de treinamento/anÃ¡lise
â”œâ”€â”€ âš™ï¸ configs/                      # ConfiguraÃ§Ãµes YAML
â””â”€â”€ ğŸ“Š data/                         # Datasets
```

## ğŸ“‹ ConfiguraÃ§Ã£o

### ğŸ¯ Dataset

O sistema usa o **Dataset-Unificado** com:
- **ğŸ“Š Tamanho**: ~2.5GB
- **ğŸ¤ Samples**: ~23.000 amostras
- **ğŸ‘¥ Speakers**: 52 speakers Ãºnicos
- **ğŸŒ Idioma**: PortuguÃªs brasileiro

### ğŸ”§ Treinamento

```yaml
# configs/training/vits2_dataset_unificado.yaml
model:
  num_speakers: 52

training:
  epochs: 200
  batch_size: 12
  learning_rate: 2e-4
  mixed_precision: true

llm_monitor:
  enabled: true
  provider: "openrouter"
  model: "anthropic/claude-3-5-sonnet-20241022"
  monitor_every_epochs: 5
```

## ğŸ¤– Monitor LLM

### ğŸ§  Funcionalidades

- **ğŸ“Š AnÃ¡lise inteligente**: Avalia mÃ©tricas a cada 5 Ã©pocas
- **âš™ï¸ Ajustes automÃ¡ticos**: Learning rate, batch size, scheduler
- **ğŸ›¡ï¸ AprovaÃ§Ã£o humana**: Para mudanÃ§as crÃ­ticas (>30%)
- **ğŸ“ˆ HistÃ³rico**: Salva anÃ¡lises e decisÃµes
- **ğŸ”„ ConfiguraÃ§Ã£o dinÃ¢mica**: Atualiza parÃ¢metros em tempo real

### ğŸ”‘ ConfiguraÃ§Ã£o API

```bash
# OpenRouter (recomendado)
export OPENROUTER_API_KEY="sua_api_key"

# Ou configure no Colab
OPENROUTER_API_KEY = "sua_api_key"  # @param {type:"string"}
```

## ğŸ“Š Monitoramento

### ğŸ“ˆ TensorBoard

```bash
# Local
tensorboard --logdir logs/tensorboard/

# Colab (automÃ¡tico)
%tensorboard --logdir logs/tensorboard/
```

### ğŸ“‹ MÃ©tricas

- **ğŸµ Loss de ReconstruÃ§Ã£o**: Qualidade da sÃ­ntese
- **ğŸ­ Loss de Adversarial**: Realismo do Ã¡udio
- **ğŸ¯ Loss de DuraÃ§Ã£o**: PrecisÃ£o temporal
- **ğŸ“Š MOS Score**: Qualidade perceptual
- **âš¡ Velocidade**: IteraÃ§Ãµes por segundo

## ğŸ¯ Roadmap

### âœ… ConcluÃ­do

- [x] Sistema VITS2 multi-speaker
- [x] Monitor LLM inteligente
- [x] Notebook Google Colab
- [x] Dataset unificado
- [x] Sistema de treinamento robusto

### ğŸš§ Em Desenvolvimento

- [ ] Interface web para inferÃªncia
- [ ] API REST para produÃ§Ã£o
- [ ] Suporte a mÃºltiplos idiomas
- [ ] Fine-tuning com poucos dados
- [ ] Controle prosÃ³dico avanÃ§ado

### ğŸ”® Futuro

- [ ] SÃ­ntese em tempo real
- [ ] Clonagem de voz zero-shot
- [ ] IntegraÃ§Ã£o com streaming
- [ ] Mobile deployment
- [ ] Plugin para DAWs

## ğŸ¤ ContribuiÃ§Ã£o

1. **Fork** o repositÃ³rio
2. **Crie** uma branch: `git checkout -b feature/nova-funcionalidade`
3. **Commit** suas mudanÃ§as: `git commit -m 'Adiciona nova funcionalidade'`
4. **Push** para a branch: `git push origin feature/nova-funcionalidade`
5. **Abra** um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- **VITS2**: [Original Paper](https://arxiv.org/abs/2307.16430)
- **BigVGAN**: [Original Repository](https://github.com/NVIDIA/BigVGAN)
- **PyTorch Lightning**: Framework de treinamento
- **Google Colab**: Plataforma de desenvolvimento

---

**ğŸ‰ ValeTTS - Transformando texto em fala com IA de Ãºltima geraÃ§Ã£o!**

[![GitHub stars](https://img.shields.io/github/stars/wallacemt/ValeTTS?style=social)](https://github.com/wallacemt/ValeTTS/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/wallacemt/ValeTTS?style=social)](https://github.com/wallacemt/ValeTTS/network/members)
