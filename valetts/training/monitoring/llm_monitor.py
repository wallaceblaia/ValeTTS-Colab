"""
Monitor de Treinamento Assistido por LLM.

Sistema principal que coordena an√°lise inteligente do progresso
de treinamento usando Claude 4 Sonnet via OpenRoutes.
"""

import json
import logging
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import requests
import torch
import yaml

from valetts.training.monitoring.config import (
    LLMAnalysisResponse,
    LLMMonitorConfig,
)
from valetts.training.monitoring.historical_telemetry import (
    HistoricalTelemetryCollector,
)
from valetts.training.monitoring.human_approval import HumanApprovalSystem
from valetts.training.monitoring.safety import SafetyValidator

logger = logging.getLogger(__name__)


class LLMTrainingMonitor:
    """
    Monitor principal para an√°lise de treinamento assistida por LLM.

    Coordena coleta de m√©tricas, an√°lise pelo Claude 4 Sonnet,
    valida√ß√£o de seguran√ßa e aplica√ß√£o de mudan√ßas din√¢micas.
    """

    def __init__(self, config: LLMMonitorConfig):
        """
        Inicializa o monitor LLM.

        Args:
            config: Configura√ß√£o do sistema de monitoramento
        """
        self.config = config
        self.safety_validator = SafetyValidator(config)

        # üîó Novos sistemas integrados
        self.human_approval = HumanApprovalSystem(timeout_seconds=60)
        self.telemetry = HistoricalTelemetryCollector(max_history_size=100)

        # Configura√ß√£o da API
        self.api_key = os.getenv(config.api_key_env)
        if config.enabled and not self.api_key:
            raise ValueError(f"API key n√£o encontrada: {config.api_key_env}")

        # Hist√≥rico de an√°lises
        self.analysis_history: List[LLMAnalysisResponse] = []

        # Configura√ß√£o din√¢mica
        self.dynamic_config_path = Path(config.dynamic_config_path)
        self.original_config_backup: Optional[Dict] = None

        # Estat√≠sticas
        self.total_analyses = 0
        self.accepted_suggestions = 0
        self.rejected_suggestions = 0

        logger.info(f"ü§ñ LLM Monitor inicializado - Enabled: {config.enabled}")

    def should_analyze(self, epoch: int, step: Optional[int] = None) -> bool:
        """
        Verifica se deve fazer an√°lise nesta √©poca/step.

        Args:
            epoch: √âpoca atual
            step: Step atual (opcional)

        Returns:
            True se deve analisar
        """
        if not self.config.enabled:
            return False

        # An√°lise por epochs
        if self.config.monitor_every_epochs > 0:
            return epoch % self.config.monitor_every_epochs == 0

        # An√°lise por steps
        if self.config.monitor_every_steps and step:
            return step % self.config.monitor_every_steps == 0

        return False

    def should_generate_report(self, epoch: int) -> bool:
        """
        Verifica se deve gerar relat√≥rio informativo nesta √©poca.

        Args:
            epoch: √âpoca atual

        Returns:
            True se deve gerar relat√≥rio
        """
        if not self.config.enabled or not getattr(
            self.config, "generate_reports", False
        ):
            return False

        report_frequency = getattr(self.config, "report_every_epochs", 5)
        return epoch > 0 and epoch % report_frequency == 0

    def add_epoch_metrics(self, metrics: Dict[str, float], epoch: int) -> None:
        """Adiciona m√©tricas da √©poca ao hist√≥rico de telemetria."""
        self.telemetry.add_epoch_metrics(metrics, epoch)

    def analyze_training_progress(
        self,
        epoch: int,
        metrics: Dict[str, float],
        current_config: Dict[str, Any],
        model_info: Optional[Dict[str, Any]] = None,
    ) -> Optional[LLMAnalysisResponse]:
        """
        Analisa progresso do treinamento usando LLM.

        Args:
            epoch: √âpoca atual
            metrics: M√©tricas de treinamento
            current_config: Configura√ß√£o atual
            model_info: Informa√ß√µes do modelo (opcional)

        Returns:
            Resposta da an√°lise LLM ou None se erro
        """
        if not self.config.enabled:
            return None

        try:
            # üîó Adicionar m√©tricas ao hist√≥rico de telemetria
            self.add_epoch_metrics(metrics, epoch)

            # Preparar dados para an√°lise (agora com contexto hist√≥rico)
            analysis_data = self._prepare_analysis_data(
                epoch, metrics, current_config, model_info
            )

            # Gerar prompt especializado
            prompt = self._generate_analysis_prompt(analysis_data)

            # Fazer requisi√ß√£o para Claude via OpenRoutes
            response = self._call_llm_api(prompt)

            if response:
                # Salvar an√°lise no hist√≥rico
                self._save_analysis_to_history(response)
                self.total_analyses += 1

                logger.info(f"‚úÖ An√°lise LLM conclu√≠da - √âpoca {epoch}")
                return response

        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise LLM: {e}")

        return None

    def generate_training_report(
        self,
        epoch: int,
        metrics: Dict[str, float],
        current_config: Dict[str, Any],
        model_info: Optional[Dict[str, Any]] = None,
    ) -> Optional[str]:
        """
        Gera relat√≥rio informativo do progresso de treinamento.

        Args:
            epoch: √âpoca atual
            metrics: M√©tricas de treinamento
            current_config: Configura√ß√£o atual
            model_info: Informa√ß√µes do modelo (opcional)

        Returns:
            Relat√≥rio em texto livre ou None se erro
        """
        if not self.config.enabled or not getattr(
            self.config, "generate_reports", False
        ):
            return None

        try:
            # Adicionar m√©tricas ao hist√≥rico de telemetria
            self.add_epoch_metrics(metrics, epoch)

            # Preparar dados para o relat√≥rio
            analysis_data = self._prepare_analysis_data(
                epoch, metrics, current_config, model_info
            )

            # Gerar prompt para relat√≥rio informativo
            prompt = self._generate_report_prompt(analysis_data)

            # Fazer requisi√ß√£o para Claude via OpenRoutes
            response = self._call_llm_report_api(prompt)

            if response:
                logger.info(f"üìä Relat√≥rio informativo gerado - √âpoca {epoch}")
                return response

        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar relat√≥rio: {e}")

        return None

    def apply_suggestions(
        self,
        analysis: LLMAnalysisResponse,
        current_config: Dict[str, Any],
        epoch: int,
    ) -> Dict[str, Any]:
        """
        Aplica sugest√µes do LLM com valida√ß√£o de seguran√ßa.

        Args:
            analysis: Resposta da an√°lise LLM
            current_config: Configura√ß√£o atual
            epoch: √âpoca atual

        Returns:
            Nova configura√ß√£o atualizada
        """
        if not analysis.config_suggestions:
            return current_config

        # Validar sugest√µes
        validated_suggestions, warnings = (
            self.safety_validator.validate_suggestions(
                analysis.config_suggestions, current_config
            )
        )

        # Log warnings
        for warning in warnings:
            logger.warning(warning)

        # Verificar mudan√ßas cr√≠ticas
        is_critical, critical_changes = (
            self.safety_validator.is_critical_change_batch(
                validated_suggestions, current_config
            )
        )

        if is_critical and self.config.require_human_approval:
            logger.warning(
                f"üö® Mudan√ßas cr√≠ticas detectadas que requerem aprova√ß√£o humana:\n"
                + "\n".join(critical_changes)
            )

            # üîó Sistema de aprova√ß√£o humana integrado
            try:
                approved, final_config = self.human_approval.request_approval(
                    epoch=epoch,
                    current_config=current_config,
                    suggested_changes=validated_suggestions,
                    llm_analysis=analysis.analysis_summary,
                )

                if approved:
                    logger.info("‚úÖ Mudan√ßas aprovadas pelo usu√°rio")
                    return final_config
                else:
                    logger.info("‚ùå Mudan√ßas rejeitadas pelo usu√°rio")
                    return current_config

            except Exception as e:
                logger.error(f"‚ùå Erro na aprova√ß√£o humana: {e}")
                # Fallback: aplicar apenas mudan√ßas n√£o-cr√≠ticas
                validated_suggestions = {
                    k: v
                    for k, v in validated_suggestions.items()
                    if not self.config.is_critical_change(
                        k, current_config.get(k, 0), v
                    )
                }

        # Aplicar mudan√ßas validadas
        if validated_suggestions:
            updated_config = current_config.copy()
            updated_config.update(validated_suggestions)

            # Salvar configura√ß√£o din√¢mica
            self._save_dynamic_config(updated_config)

            # Registrar mudan√ßas
            self.safety_validator.record_change(epoch, validated_suggestions)
            self.accepted_suggestions += len(validated_suggestions)

            logger.info(
                f"üîÑ Aplicadas {len(validated_suggestions)} sugest√µes LLM na √©poca {epoch}"
            )

            for param, value in validated_suggestions.items():
                logger.info(
                    f"   {param}: {current_config.get(param)} ‚Üí {value}"
                )

            return updated_config

        else:
            logger.info("‚ÑπÔ∏è Nenhuma sugest√£o v√°lida para aplicar")
            return current_config

    def _prepare_analysis_data(
        self,
        epoch: int,
        metrics: Dict[str, float],
        config: Dict[str, Any],
        model_info: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Prepara dados para an√°lise LLM com contexto hist√≥rico rico."""
        # Filtrar apenas m√©tricas monitoradas
        filtered_metrics = {
            k: v
            for k, v in metrics.items()
            if k in self.config.metrics_to_monitor
        }

        # üîó Obter dados contextuais da telemetria hist√≥rica
        telemetry_data = self.telemetry.get_contextual_data(epoch)

        # Contexto de an√°lises LLM anteriores
        llm_analysis_context = []
        if len(self.analysis_history) > 0:
            recent_analyses = self.analysis_history[
                -self.config.include_context_epochs :
            ]
            llm_analysis_context = [
                {
                    "epoch": a.epoch,
                    "status": a.overall_status,
                    "summary": a.analysis_summary,
                }
                for a in recent_analyses
            ]

        return {
            "current_epoch": epoch,
            "metrics": filtered_metrics,
            "config": config,
            "model_info": model_info or {},
            "safe_ranges": self.config.get_safe_ranges(),
            "alert_thresholds": {
                "loss_spike": self.config.loss_spike_threshold,
                "grad_norm": self.config.grad_norm_threshold,
                "memory_usage": self.config.memory_usage_threshold,
            },
            # üîó Contexto hist√≥rico enriquecido
            "historical_telemetry": telemetry_data,
            "llm_analysis_context": llm_analysis_context,
            "timestamp": datetime.now().isoformat(),
        }

    def _generate_analysis_prompt(self, data: Dict[str, Any]) -> str:
        """Gera prompt especializado para an√°lise VITS2 com contexto temporal."""

        # Determinar fase do treinamento baseado na √©poca
        epoch = data["current_epoch"]
        if epoch < 5:
            phase = "INICIALIZA√á√ÉO"
        elif epoch < 20:
            phase = "ESTABILIZA√á√ÉO"
        elif epoch < 50:
            phase = "CONVERG√äNCIA_INICIAL"
        else:
            phase = "REFINAMENTO"

        prompt = f"""Voc√™ √© um especialista em treinamento de modelos VITS2 (Variational Inference Text-to-Speech).
Analise os dados de treinamento fornecidos considerando o contexto temporal e as caracter√≠sticas espec√≠ficas do VITS2.

## CONTEXTO DO TREINAMENTO

**√âPOCA ATUAL:** {epoch} (Fase: {phase})
**Timestamp:** {data['timestamp']}

## CONHECIMENTO ESPEC√çFICO VITS2:

### Comportamento Normal por Fase:
- **√âPOCAS 0-5 (INICIALIZA√á√ÉO):**
  * KL Loss = Infinity √© NORMAL (posterior/prior n√£o alinhados)
  * Mel Loss alta (>5.0) √© esperada
  * Discriminadores podem n√£o estar ativos ainda

- **√âPOCAS 5-20 (ESTABILIZA√á√ÉO):**
  * KL Loss deve come√ßar a diminuir gradualmente
  * Mel Loss deve mostrar tend√™ncia de queda
  * Adversarial loss deve se tornar ativa

- **√âPOCAS 20+ (CONVERG√äNCIA):**
  * Todas as losses devem convergir
  * KL Loss < 1.0 √© bom sinal
  * Mel Loss < 2.0 √© excelente

### Losses VITS2:
- **mel_loss:** Reconstru√ß√£o mel-spectrogram (target: <2.0)
- **kl_loss:** KL divergence VAE (NORMAL ser infinity no in√≠cio!)
- **adv_loss:** Adversarial discriminator (pode demorar para ativar)
- **fm_loss:** Feature matching (estabiliza training adversarial)
- **duration_loss:** Alinhamento texto-√°udio

## DADOS ATUAIS

### M√©tricas da √âpoca {epoch}:
{json.dumps(data['metrics'], indent=2)}

### Configura√ß√£o Atual:
{json.dumps(data['config'], indent=2)}

### Ranges Seguros:
{json.dumps(data['safe_ranges'], indent=2)}

### Hist√≥rico (√∫ltimas √©pocas):
{json.dumps(data['historical_telemetry'], indent=2)}

### An√°lises LLM Anteriores:
{json.dumps(data['llm_analysis_context'], indent=2)}

## INSTRU√á√ïES DE AN√ÅLISE

Considere SEMPRE a √©poca atual ({epoch}) e a fase do treinamento ({phase}) para suas recomenda√ß√µes.

### Regras Espec√≠ficas por Fase:
- **INICIALIZA√á√ÉO (0-5):** Foque em estabilidade, KL infinity √© OK
- **ESTABILIZA√á√ÉO (5-20):** Monitor KL converg√™ncia, ajustar LR gradualmente
- **CONVERG√äNCIA (20+):** Otimizar todas as losses, refinamento fino

Responda APENAS com um JSON v√°lido seguindo EXATAMENTE esta estrutura:

{{
    "overall_status": "healthy|warning|critical",
    "confidence_score": 0.95,
    "analysis_summary": "Resumo da an√°lise em portugu√™s",
    "config_suggestions": {{
        "learning_rate": 0.001,
        "batch_size": 32,
        "loss_weight_mel": 1.0
    }},
    "observations": [
        "Observa√ß√£o espec√≠fica 1",
        "Observa√ß√£o espec√≠fica 2"
    ],
    "recommended_actions": [
        "A√ß√£o recomendada 1",
        "A√ß√£o recomendada 2"
    ],
    "alerts": [
        "Alerta importante se houver"
    ],
    "next_checkpoints": [
        "Verificar na √©poca X",
        "Monitorar m√©trica Y"
    ],
    "timestamp": "{data['timestamp']}",
    "epoch": {data['current_epoch']},
    "model_used": "claude-3-5-sonnet"
}}

## DIRETRIZES IMPORTANTES

1. **SEGURAN√áA**: Sugira apenas mudan√ßas dentro dos ranges seguros fornecidos
2. **GRADUALIDADE**: Evite mudan√ßas abruptas (max 2x para LR, batch size)
3. **CONTEXTO**: Considere o hist√≥rico e tend√™ncias das m√©tricas
4. **M√âTRICAS VITS2**: Foque em mel_loss, kl_loss, adversarial_loss
5. **ESTABILIDADE**: Priorize estabilidade sobre converg√™ncia r√°pida

Responda APENAS com o JSON, sem texto adicional."""

        return prompt

    def _generate_report_prompt(self, data: Dict[str, Any]) -> str:
        """Gera prompt especializado para relat√≥rios informativos."""

        # Determinar fase do treinamento
        epoch = data["current_epoch"]
        if epoch < 5:
            phase = "INICIALIZA√á√ÉO"
        elif epoch < 20:
            phase = "ESTABILIZA√á√ÉO"
        elif epoch < 50:
            phase = "CONVERG√äNCIA_INICIAL"
        else:
            phase = "REFINAMENTO"

        prompt = f"""Voc√™ √© um especialista em treinamento de modelos VITS2 (Variational Inference Text-to-Speech).
Gere um RELAT√ìRIO INFORMATIVO detalhado sobre o progresso do treinamento, explicando cada m√©trica e tend√™ncia de forma clara e educativa.

## CONTEXTO DO TREINAMENTO

**√âPOCA ATUAL:** {epoch} (Fase: {phase})
**Timestamp:** {data['timestamp']}

## DADOS DO TREINAMENTO

### M√©tricas da √âpoca {epoch}:
{json.dumps(data['metrics'], indent=2)}

### Hist√≥rico das √öltimas √âpocas:
{json.dumps(data['historical_telemetry'], indent=2)}

### Configura√ß√£o Atual:
Learning Rate: {data['config'].get('learning_rate', 'N/A')}
Batch Size: {data['config'].get('batch_size', 'N/A')}
Mel Loss Weight: {data['config'].get('mel_loss_weight', 'N/A')}

## INSTRU√á√ïES PARA O RELAT√ìRIO

Crie um relat√≥rio informativo e educativo que inclua:

1. **RESUMO GERAL**: Estado atual do treinamento em uma frase
2. **AN√ÅLISE DAS M√âTRICAS**: Explique cada perda e o que significa:
   - mel_loss: Como est√° a qualidade de reconstru√ß√£o do mel-spectrograma
   - kl_loss: Comportamento da diverg√™ncia KL (normal ser alta no in√≠cio)
   - adv_loss: Status do treinamento adversarial
   - outras losses relevantes
3. **TEND√äNCIAS**: Como as m√©tricas est√£o evoluindo ao longo do tempo
4. **FASE ATUAL**: O que √© esperado nesta fase ({phase}) do treinamento
5. **PONTOS DE ATEN√á√ÉO**: Aspectos que merecem observa√ß√£o
6. **PR√ìXIMOS MARCOS**: O que esperar nas pr√≥ximas √©pocas

## DIRETRIZES

- Use linguagem clara e educativa
- Explique o SIGNIFICADO de cada m√©trica, n√£o apenas os valores
- Compare com o que √© ESPERADO para esta fase
- Destaque TEND√äNCIAS positivas ou preocupantes
- Seja espec√≠fico sobre VITS2 e suas caracter√≠sticas
- Use emojis para tornar mais visual: üìà üìâ ‚ö†Ô∏è ‚úÖ üéØ

Responda em TEXTO LIVRE (n√£o JSON), de forma conversacional e informativa."""

        return prompt

    def _call_llm_report_api(self, prompt: str) -> Optional[str]:
        """Faz chamada para API do Claude para gerar relat√≥rios informativos."""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://valetts.dev",
                "X-Title": "ValeTTS Training Reporter",
            }

            payload = {
                "model": self.config.model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 3000,  # Mais tokens para relat√≥rios detalhados
                "temperature": 0.3,  # Mais criativo para relat√≥rios
            }

            response = requests.post(
                f"{self.config.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=60,
            )

            response.raise_for_status()

            # Extrair resposta
            result = response.json()
            content = result["choices"][0]["message"]["content"]

            return content

        except requests.RequestException as e:
            logger.error(f"‚ùå Erro na requisi√ß√£o API para relat√≥rio: {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado na API LLM para relat√≥rio: {e}")
            return None

    def _call_llm_api(self, prompt: str) -> Optional[LLMAnalysisResponse]:
        """Faz chamada para API do Claude via OpenRoutes."""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://valetts.dev",
                "X-Title": "ValeTTS Training Monitor",
            }

            payload = {
                "model": self.config.model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 2048,
                "temperature": 0.1,  # Baixa temperatura para consist√™ncia
            }

            response = requests.post(
                f"{self.config.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=60,
            )

            response.raise_for_status()

            # Extrair resposta
            result = response.json()
            content = result["choices"][0]["message"]["content"]

            # Parse JSON da resposta
            try:
                analysis_data = json.loads(content)
                return LLMAnalysisResponse(**analysis_data)
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Erro parsing JSON da resposta LLM: {e}")
                logger.debug(f"Resposta bruta: {content}")
                return None

        except requests.RequestException as e:
            logger.error(f"‚ùå Erro na requisi√ß√£o API: {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado na API LLM: {e}")
            return None

    def _save_analysis_to_history(self, analysis: LLMAnalysisResponse) -> None:
        """Salva an√°lise no hist√≥rico."""
        self.analysis_history.append(analysis)

        # Manter apenas hist√≥rico recente
        if len(self.analysis_history) > self.config.max_history_entries:
            self.analysis_history = self.analysis_history[
                -self.config.max_history_entries :
            ]

    def _save_dynamic_config(self, config: Dict[str, Any]) -> None:
        """Salva configura√ß√£o din√¢mica em arquivo."""
        try:
            # Criar diret√≥rio se n√£o existir
            self.dynamic_config_path.parent.mkdir(parents=True, exist_ok=True)

            # Backup da configura√ß√£o original (primeira vez)
            if (
                self.original_config_backup is None
                and self.dynamic_config_path.exists()
            ):
                with open(self.dynamic_config_path, "r") as f:
                    self.original_config_backup = yaml.safe_load(f)

            # Salvar nova configura√ß√£o
            with open(self.dynamic_config_path, "w") as f:
                yaml.dump(config, f, indent=2, allow_unicode=True)

            logger.debug(
                f"üíæ Configura√ß√£o din√¢mica salva: {self.dynamic_config_path}"
            )

        except Exception as e:
            logger.error(f"‚ùå Erro salvando configura√ß√£o din√¢mica: {e}")

    def get_statistics(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas do monitor."""
        # Calcular sugest√µes aplicadas/rejeitadas do hist√≥rico
        suggestions_applied = 0
        suggestions_rejected = 0
        critical_changes = 0

        for analysis in self.analysis_history:
            if hasattr(analysis, "config_suggestions"):
                suggestions_count = len(analysis.config_suggestions)
                # Por enquanto, assumir que sugest√µes cr√≠ticas s√£o rejeitadas
                if analysis.overall_status == "critical":
                    suggestions_rejected += suggestions_count
                    critical_changes += 1
                else:
                    suggestions_applied += suggestions_count

        return {
            "total_analyses": self.total_analyses,
            "suggestions_applied": suggestions_applied,
            "suggestions_rejected": suggestions_rejected,
            "critical_changes": critical_changes,
            "acceptance_rate": (
                suggestions_applied / max(1, self.total_analyses)
            ),
            "history_length": len(self.analysis_history),
            "enabled": self.config.enabled,
        }
