{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéôÔ∏è ValeTTS - Treinamento VITS2 no Google Colab Pro\n",
        "\n",
        "## ‚ö†Ô∏è **INSTRU√á√ïES IMPORTANTES:**\n",
        "1. **Execute as c√©lulas em ordem**\n",
        "2. **Configure sua API key do OpenRouter** na c√©lula 4\n",
        "3. **Monitore pelo TensorBoard e relat√≥rios LLM**\n",
        "4. **Logs salvos automaticamente no Google Drive**\n",
        "\n",
        "### üéØ **Recursos Ativados:**\n",
        "- ü§ñ **Monitoramento LLM via OpenRouter** (relat√≥rios autom√°ticos)\n",
        "- üìä **TensorBoard** (m√©tricas em tempo real)\n",
        "- üíæ **Checkpoints autom√°ticos** (Google Drive)\n",
        "- üéµ **Amostras de √°udio** (a cada 10 √©pocas)\n",
        "\n",
        "### üîß **Configura√ß√£o otimizada para:**\n",
        "- Tesla T4 (15GB VRAM) - Batch 6\n",
        "- Tesla P100 (16GB VRAM) - Batch 8\n",
        "- Tesla V100 (16GB VRAM) - Batch 10\n",
        "- Mixed precision (FP16)\n",
        "- Gradient accumulation 4x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Verificar GPU e conectar Google Drive\n",
        "!nvidia-smi\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import psutil\n",
        "\n",
        "# Conectar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verificar recursos\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.cuda.get_device_name(0)\n",
        "    vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    \n",
        "    # Configurar batch size baseado na GPU\n",
        "    if 'T4' in device:\n",
        "        recommended_batch = 6\n",
        "    elif 'P100' in device:\n",
        "        recommended_batch = 8\n",
        "    elif 'V100' in device or 'A100' in device:\n",
        "        recommended_batch = 10\n",
        "    else:\n",
        "        recommended_batch = 8\n",
        "else:\n",
        "    device = \"CPU only\"\n",
        "    vram = 0\n",
        "    recommended_batch = 2\n",
        "\n",
        "ram = psutil.virtual_memory().total / 1e9\n",
        "disk = psutil.disk_usage('/').free / 1e9\n",
        "\n",
        "print(f\"üî• GPU: {device}\")\n",
        "print(f\"üíæ VRAM: {vram:.1f} GB\")\n",
        "print(f\"üß† RAM: {ram:.1f} GB\")\n",
        "print(f\"üíΩ Disk Free: {disk:.1f} GB\")\n",
        "print(f\"üìä Batch recomendado: {recommended_batch}\")\n",
        "print(f\"‚úÖ Google Drive conectado\")\n",
        "\n",
        "# Salvar configura√ß√£o autom√°tica\n",
        "GPU_CONFIG = {\n",
        "    'device': device,\n",
        "    'vram': vram,\n",
        "    'recommended_batch': recommended_batch\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Clonar c√≥digo e instalar depend√™ncias\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "# Remover diret√≥rio se j√° existir\n",
        "if os.path.exists('/content/ValeTTS-Colab'):\n",
        "    !rm -rf /content/ValeTTS-Colab\n",
        "\n",
        "# Clonar reposit√≥rio\n",
        "print(\"üì¶ Clonando c√≥digo do GitHub...\")\n",
        "!git clone https://github.com/wallaceblaia/ValeTTS-Colab.git\n",
        "os.chdir('/content/ValeTTS-Colab')\n",
        "\n",
        "print(\"üîç Estrutura do projeto:\")\n",
        "!ls -la\n",
        "\n",
        "# Instalar depend√™ncias\n",
        "print(\"\\nüìö Instalando depend√™ncias...\")\n",
        "%pip install -r requirements.txt --quiet\n",
        "%pip install tensorboard --quiet\n",
        "%pip install openai --quiet  # Para OpenRouter\n",
        "\n",
        "# Otimizar Tensor Cores\n",
        "import torch\n",
        "torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "print(\"\\n‚úÖ Depend√™ncias instaladas\")\n",
        "print(\"‚úÖ Tensor Cores otimizados\")\n",
        "print(\"‚úÖ TensorBoard pronto\")\n",
        "print(\"‚úÖ OpenRouter configurado\")\n",
        "\n",
        "# Verificar vers√µes\n",
        "import lightning as L\n",
        "import librosa\n",
        "print(f\"\\nüîß PyTorch: {torch.__version__}\")\n",
        "print(f\"üîß Lightning: {L.__version__}\")\n",
        "print(f\"üîß Librosa: {librosa.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Extrair dataset do Google Drive\n",
        "import tarfile\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Verificar dataset\n",
        "drive_dataset = \"/content/drive/MyDrive/ValeTTS/Dataset-Unificado.tar.gz\"\n",
        "print(f\"üîç Procurando dataset: {drive_dataset}\")\n",
        "\n",
        "if not os.path.exists(drive_dataset):\n",
        "    print(\"‚ùå Dataset n√£o encontrado!\")\n",
        "    print(\"\\nüìã Instru√ß√µes para upload:\")\n",
        "    print(\"   1. Acesse: https://drive.google.com\")\n",
        "    print(\"   2. Crie pasta: ValeTTS\")\n",
        "    print(\"   3. Fa√ßa upload: Dataset-Unificado.tar.gz\")\n",
        "    print(\"   4. Caminho final: /content/drive/MyDrive/ValeTTS/Dataset-Unificado.tar.gz\")\n",
        "    raise FileNotFoundError(\"Dataset n√£o encontrado no Google Drive\")\n",
        "\n",
        "# Verificar tamanho\n",
        "file_size = os.path.getsize(drive_dataset) / 1e9\n",
        "print(f\"üìÅ Tamanho do arquivo: {file_size:.1f} GB\")\n",
        "\n",
        "# Extrair dataset\n",
        "local_path = \"/content/ValeTTS-Colab/data/generated\"\n",
        "Path(local_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"üì¶ Extraindo dataset... (pode levar alguns minutos)\")\n",
        "start_time = time.time()\n",
        "\n",
        "with tarfile.open(drive_dataset, 'r:gz') as tar:\n",
        "    tar.extractall(local_path)\n",
        "\n",
        "extract_time = time.time() - start_time\n",
        "print(f\"‚è±Ô∏è  Extra√ß√£o conclu√≠da em {extract_time:.1f}s\")\n",
        "\n",
        "# Verificar extra√ß√£o\n",
        "dataset_path = f\"{local_path}/Dataset-Unificado\"\n",
        "if os.path.exists(dataset_path):\n",
        "    audio_files = list(Path(f\"{dataset_path}/audio/raw\").glob(\"*.wav\"))\n",
        "    metadata_size = os.path.getsize(f\"{dataset_path}/metadata.csv\") / 1e6\n",
        "    \n",
        "    print(f\"‚úÖ Dataset extra√≠do para: {dataset_path}\")\n",
        "    print(f\"üéµ Arquivos de √°udio: {len(audio_files):,}\")\n",
        "    print(f\"üìã Metadata: {metadata_size:.1f} MB\")\n",
        "    \n",
        "    # Verificar alguns arquivos\n",
        "    sample_files = audio_files[:3]\n",
        "    print(f\"\\nüîç Amostras de arquivos:\")\n",
        "    for f in sample_files:\n",
        "        size = f.stat().st_size / 1024\n",
        "        print(f\"   - {f.name} ({size:.1f} KB)\")\n",
        "else:\n",
        "    print(\"‚ùå Erro na extra√ß√£o do dataset!\")\n",
        "    raise Exception(\"Falha na extra√ß√£o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. ‚ö†Ô∏è CONFIGURE SUA API KEY DO OPENROUTER AQUI ‚ö†Ô∏è\n",
        "\n",
        "# ============================================\n",
        "# CONFIGURA√á√ÉO DO OPENROUTER\n",
        "# ============================================\n",
        "OPENROUTER_API_KEY = \"sk-or-v1-your-api-key-here\"  # ‚Üê ALTERE AQUI\n",
        "\n",
        "# Modelo a usar (recomendado: claude ou gpt-4)\n",
        "LLM_MODEL = \"anthropic/claude-3.5-sonnet\"  # ou \"openai/gpt-4o\"\n",
        "\n",
        "# OU desabilite o monitoramento LLM:\n",
        "ENABLE_LLM_MONITORING = True  # ‚Üê Mude para False se n√£o quiser LLM\n",
        "ENABLE_TENSORBOARD = True     # ‚Üê TensorBoard sempre recomendado\n",
        "ENABLE_REPORTS = True         # ‚Üê Relat√≥rios em markdown\n",
        "# ============================================\n",
        "\n",
        "print(\"üîß Configura√ß√£o de Monitoramento:\")\n",
        "print(f\"   ü§ñ LLM Monitoring: {'‚úÖ Ativo' if ENABLE_LLM_MONITORING else '‚ùå Desabilitado'}\")\n",
        "print(f\"   üìä TensorBoard: {'‚úÖ Ativo' if ENABLE_TENSORBOARD else '‚ùå Desabilitado'}\")\n",
        "print(f\"   üìã Relat√≥rios: {'‚úÖ Ativo' if ENABLE_REPORTS else '‚ùå Desabilitado'}\")\n",
        "\n",
        "if ENABLE_LLM_MONITORING:\n",
        "    if OPENROUTER_API_KEY == \"sk-or-v1-your-api-key-here\":\n",
        "        print(\"\\n‚ö†Ô∏è  ATEN√á√ÉO: Configure sua API key do OpenRouter acima!\")\n",
        "        print(\"   1. Acesse: https://openrouter.ai/keys\")\n",
        "        print(\"   2. Crie uma API key\")\n",
        "        print(\"   3. Cole acima em OPENROUTER_API_KEY\")\n",
        "        print(\"   4. Ou mude ENABLE_LLM_MONITORING para False\")\n",
        "    else:\n",
        "        print(f\"   üîë API Key configurada: {OPENROUTER_API_KEY[:20]}...\")\n",
        "        print(f\"   üß† Modelo LLM: {LLM_MODEL}\")\n",
        "        print(\"   ‚úÖ Monitoramento LLM pronto!\")\n",
        "\n",
        "# Testar conectividade se API key configurada\n",
        "if ENABLE_LLM_MONITORING and OPENROUTER_API_KEY != \"sk-or-v1-your-api-key-here\":\n",
        "    try:\n",
        "        import requests\n",
        "        response = requests.get(\n",
        "            \"https://openrouter.ai/api/v1/models\",\n",
        "            headers={\"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\"},\n",
        "            timeout=10\n",
        "        )\n",
        "        if response.status_code == 200:\n",
        "            print(\"   üåê Conectividade OpenRouter: ‚úÖ OK\")\n",
        "        else:\n",
        "            print(f\"   üåê Conectividade OpenRouter: ‚ö†Ô∏è  Status {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   üåê Conectividade OpenRouter: ‚ùå Erro: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Configura√ß√£o de monitoramento finalizada!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Criar configura√ß√£o otimizada para Colab\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Configura√ß√£o otimizada baseada na GPU detectada\n",
        "batch_size = GPU_CONFIG['recommended_batch']\n",
        "\n",
        "config = {\n",
        "    'model': {\n",
        "        'name': 'VITS2',\n",
        "        'text_encoder': {\n",
        "            'hidden_channels': 128,  # Otimizado para Colab\n",
        "            'filter_channels': 512,  # Reduzido para economia de VRAM\n",
        "            'n_heads': 2,\n",
        "            'n_layers': 4,           # Reduzido de 6\n",
        "            'kernel_size': 3,\n",
        "            'p_dropout': 0.1\n",
        "        },\n",
        "        'generator': {\n",
        "            'inter_channels': 128,\n",
        "            'hidden_channels': 128,\n",
        "            'filter_channels': 512,\n",
        "            'n_heads': 2,\n",
        "            'n_layers': 4,\n",
        "            'resblock': '1',\n",
        "            'resblock_kernel_sizes': [3, 7, 11],\n",
        "            'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
        "            'upsample_rates': [8, 8, 2, 2],\n",
        "            'upsample_initial_channel': 512,\n",
        "            'upsample_kernel_sizes': [16, 16, 4, 4]\n",
        "        },\n",
        "        'discriminator': {\n",
        "            'periods': [2, 3, 5, 7, 11],\n",
        "            'period_discriminator_params': {\n",
        "                'channels': 32,        # Reduzido para economia\n",
        "                'max_downsample_channels': 512\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    'data': {\n",
        "        'dataset_path': 'data/generated/Dataset-Unificado',\n",
        "        'batch_size': batch_size,\n",
        "        'sample_rate': 22050,\n",
        "        'hop_length': 256,\n",
        "        'win_length': 1024,\n",
        "        'n_mel': 80,\n",
        "        'n_fft': 1024,\n",
        "        'segment_size': 8192,      # Otimizado para Colab\n",
        "        'num_workers': 2           # Limitado no Colab\n",
        "    },\n",
        "    'training': {\n",
        "        'learning_rate': 2e-4,\n",
        "        'adam_b1': 0.8,\n",
        "        'adam_b2': 0.99,\n",
        "        'lr_decay': 0.999875,\n",
        "        'batch_size': batch_size,\n",
        "        'fp16_run': True,          # Mixed precision essencial\n",
        "        'max_epochs': 200,\n",
        "        'gradient_accumulation_steps': 4,  # Compensar batch menor\n",
        "        'gradient_clip_val': 1.0,\n",
        "        'warmup_epochs': 10,\n",
        "        'save_every_epoch': 10,\n",
        "        'validate_every_n_epoch': 5\n",
        "    },\n",
        "    'logging': {\n",
        "        'checkpoint_dir': '/content/drive/MyDrive/ValeTTS/checkpoints',\n",
        "        'log_dir': '/content/drive/MyDrive/ValeTTS/logs',\n",
        "        'sample_dir': '/content/drive/MyDrive/ValeTTS/samples',\n",
        "        'report_dir': '/content/drive/MyDrive/ValeTTS/reports',\n",
        "        'tensorboard_enabled': ENABLE_TENSORBOARD\n",
        "    },\n",
        "    'llm_monitoring': {\n",
        "        'enabled': ENABLE_LLM_MONITORING,\n",
        "        'provider': 'openrouter',\n",
        "        'api_key': OPENROUTER_API_KEY if ENABLE_LLM_MONITORING else '',\n",
        "        'model': LLM_MODEL,\n",
        "        'base_url': 'https://openrouter.ai/api/v1',\n",
        "        'monitor_every_n_epochs': 5,\n",
        "        'save_reports': ENABLE_REPORTS,\n",
        "        'max_tokens': 2000,\n",
        "        'temperature': 0.3\n",
        "    },\n",
        "    'sample_generation': {\n",
        "        'enabled': True,\n",
        "        'every_n_epochs': 10,\n",
        "        'num_samples': 3,\n",
        "        'sample_texts': [\n",
        "            'Ol√°, este √© um teste do modelo ValeTTS.',\n",
        "            'A s√≠ntese de voz em portugu√™s brasileiro funciona perfeitamente.',\n",
        "            'Obrigado por usar o ValeTTS no Google Colab.'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Criar todos os diret√≥rios necess√°rios\n",
        "directories = [\n",
        "    '/content/drive/MyDrive/ValeTTS/checkpoints',\n",
        "    '/content/drive/MyDrive/ValeTTS/logs',\n",
        "    '/content/drive/MyDrive/ValeTTS/samples', \n",
        "    '/content/drive/MyDrive/ValeTTS/reports'\n",
        "]\n",
        "\n",
        "for dir_path in directories:\n",
        "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Salvar configura√ß√£o\n",
        "config_path = Path('configs/training/vits2_colab_openrouter.yaml')\n",
        "config_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(config, f, default_flow_style=False, allow_unicode=True)\n",
        "\n",
        "print(\"‚úÖ Configura√ß√£o criada e salva!\")\n",
        "print(f\"üìÅ Arquivo: {config_path}\")\n",
        "print(f\"üî• GPU detectada: {GPU_CONFIG['device']}\")\n",
        "print(f\"üìä Batch size: {batch_size}\")\n",
        "print(f\"üß† Gradient accumulation: {config['training']['gradient_accumulation_steps']}\")\n",
        "print(f\"üíæ Checkpoints: a cada {config['training']['save_every_epoch']} √©pocas\")\n",
        "print(f\"üéµ Amostras: a cada {config['sample_generation']['every_n_epochs']} √©pocas\")\n",
        "print(f\"ü§ñ LLM: {'Ativo' if ENABLE_LLM_MONITORING else 'Desabilitado'}\")\n",
        "print(f\"üìä TensorBoard: {'Ativo' if ENABLE_TENSORBOARD else 'Desabilitado'}\")\n",
        "print(\"\\nüéØ Configura√ß√£o otimizada para Google Colab Pro!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. üöÄ INICIAR TREINAMENTO COM MONITORAMENTO COMPLETO\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "print(\"üéØ INICIANDO TREINAMENTO VITS2 NO GOOGLE COLAB PRO!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"‚è∞ In√≠cio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"üî• GPU: {GPU_CONFIG['device']} ({GPU_CONFIG['vram']:.1f}GB VRAM)\")\n",
        "print(f\"üìä Batch size: {batch_size} (gradient acc: 4x)\")\n",
        "print(f\"üß† Modelo: ~354M par√¢metros\")\n",
        "print(f\"üìà Dataset: 22,910 amostras de √°udio\")\n",
        "print(f\"üéôÔ∏è Falantes: 52 vozes diferentes\")\n",
        "print(\"\")\n",
        "print(\"üîç MONITORAMENTO ATIVO:\")\n",
        "if ENABLE_LLM_MONITORING:\n",
        "    print(f\"   ü§ñ LLM Reports: {LLM_MODEL} via OpenRouter\")\n",
        "    print(f\"       üìã Relat√≥rios a cada 5 √©pocas\")\n",
        "if ENABLE_TENSORBOARD:\n",
        "    print(f\"   üìä TensorBoard: http://localhost:6006\")\n",
        "    print(f\"       üìà M√©tricas em tempo real\")\n",
        "print(f\"   üíæ Checkpoints: Google Drive (a cada 10 √©pocas)\")\n",
        "print(f\"   üéµ Amostras: Google Drive (a cada 10 √©pocas)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Iniciar TensorBoard em background se habilitado\n",
        "if ENABLE_TENSORBOARD:\n",
        "    print(\"üöÄ Iniciando TensorBoard...\")\n",
        "    tensorboard_process = subprocess.Popen([\n",
        "        'tensorboard', '--logdir', '/content/drive/MyDrive/ValeTTS/logs',\n",
        "        '--host', '0.0.0.0', '--port', '6006'\n",
        "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    \n",
        "    # Aguardar TensorBoard inicializar\n",
        "    import time\n",
        "    time.sleep(3)\n",
        "    print(\"üìä TensorBoard iniciado! Acesse: http://localhost:6006\")\n",
        "\n",
        "print(\"\\nüéØ EXECUTANDO TREINAMENTO...\")\n",
        "print(\"‚è≥ Este processo levar√° v√°rias horas\")\n",
        "print(\"üì± Monitore pelo TensorBoard e relat√≥rios no Google Drive\")\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "# EXECUTAR TREINAMENTO\n",
        "!python scripts/train_vits2.py --config configs/training/vits2_colab_openrouter.yaml\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"‚è∞ Finalizado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"üéâ Treinamento conclu√≠do!\")\n",
        "print(\"üìÅ Verifique os resultados no Google Drive: /ValeTTS/\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}